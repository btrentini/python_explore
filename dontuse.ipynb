{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING BOOKING CHURN\n",
    "## Objective\n",
    "<p> This program intends to predict if a new booking is prone to churn </p>\n",
    "\n",
    "## Value added\n",
    "<p> Detecting the type of booking prone to cancellation can help us: </p>\n",
    "<p>\n",
    "<ol>\n",
    "<li> - Help our clients to follow up with their clients prior to the their trip</li>\n",
    "<li> - Have specific marketing campaigns to those prone to CHURN and reduce it</li>\n",
    "<li> - Identify potential revenue opportunities by applying extra charges</li>\n",
    "</ol>\n",
    "   </p>\n",
    "\n",
    "## Input / Output\n",
    "<p> Given a historical series of bookings and their attributes such as number of room nights, country, number of adults, rate plan, currency Etc, </p>\n",
    "<p> Can we predict if a new booking is prone to CHURN? </p>\n",
    "<p> If so, create an alers (or report) so that we can follow up </p>\n",
    "\n",
    "## Caveats and measuring performance\n",
    "<p> All logistic regression algorithms is also prone to:\n",
    " <ol>\n",
    "     <li> False Positives - FP, </li>\n",
    "    <li> False Negatives - FN, </li>\n",
    "    <li> True Negatives - TN and </li>\n",
    "    <li> True Positives - TP </li>\n",
    " </ol></p>\n",
    "<p> To maximise users' confidence, we'll set a series of metrics: \n",
    "\n",
    "+ Precision: (TP / (TP + FP)) > 0.7\n",
    "+ Recall: (TP / (TP + FN)) > 0.7\n",
    "</p>\n",
    "<p> In case we have an unbalanced dataset, which is likely the case, we need to balance Precision and Recall using \n",
    "+ F1 Score\n",
    "+ Accuracy\n",
    "+ Area Under ROC Curve (AUROC) which represents the likelihood of a model distinguishing observations between two classes. In very simple terms, AUROC gives a single measure of how a model’s true positive rate and false positive rate change with different threshold values. The closer a model’s AUROC score is to 1, the better it is. </p>\n",
    "\n",
    "## Measuring Financial Impact\n",
    "<p> Select a specific client with a good amount of Cancelled Bookings </p>\n",
    "<p> Measure CHURN rate on T0 (Avg of previous 4W) and Financial Impact in Gross Sales </p>\n",
    "<p> Start using the mechanism and stop on T12 (after 4W) and measure CHURN Rate and Financial Impact of the Delta </p>\n",
    "<p> <b> Caveat </b> Checkin Window can skim the resultts </p>\n",
    "\n",
    "## FAQ\n",
    "### Why Logistic Regression?\n",
    "<p> One of the simplest way to get started with classification. There exists plenty of methods and whilst Precision / Recall vary depending on model selection and attribute selection, we need to start from somewhere </p>\n",
    "\n",
    "### Difference between Linear and Logistic Regression?\n",
    "<p> Linear Regression outputs values in a continuous manner and Logistic Regression outputs a probablistic value. Hence, while logistic regression is concerned about likelihood of \"This or That\" to be \"True or False\", linear regression concerns about predicting a value. </p> \n",
    "\n",
    "### How do you define True or False in Logistic Regression?\n",
    "<p> There are several ways. Either arbitrary or using algorithms. To start with, we'll use arbitrary tresholds based on the confusion matrix </p>\n",
    "\n",
    "### Why Cancellations?\n",
    "<p> Because it can help us have an imediate financial impact if we can decrease it </p>\n",
    "\n",
    "### How to improve Predictions?\n",
    "<p> There are several ways </p>\n",
    "+ BUilding other models and comparing metrics (precision, recall, f1, accuracy...) </p>\n",
    "+ By measuring overfit / high-bias and adjusting the number of attributes accordingly or adjusting \"Cost Functions\" etc\n",
    "+ Having more historical data may not help in some cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T14:45:25.647079Z",
     "start_time": "2018-08-24T14:45:12.652641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.10586-SP0\n",
      "Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "NumPy 1.15.0\n",
      "Matplotlib 2.2.3\n",
      "Seaborn 0.9.0\n",
      "SciPy 1.1.0\n",
      "Scikit-Learn 0.19.1\n",
      "Pandas 0.23.0\n"
     ]
    }
   ],
   "source": [
    "# Health Check - Use this to debug case errors appear\n",
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import matplotlib.pyplot; print(\"Matplotlib\", matplotlib.__version__)\n",
    "import seaborn; print(\"Seaborn\", seaborn.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)\n",
    "import pandas; print(\"Pandas\", pandas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T08:55:37.769923Z",
     "start_time": "2018-08-24T08:55:37.026828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing all libraries that we're gonna need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T08:56:45.168425Z",
     "start_time": "2018-08-24T08:56:21.139373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake version:  2.54.2\n"
     ]
    }
   ],
   "source": [
    "# Gets the data from Snowflake\n",
    "eng = create_engine(\n",
    "    '******://{user}:{password}@{account}/'.format(\n",
    "        user='*****',\n",
    "        password='****',\n",
    "        account='******',\n",
    "    )\n",
    ")\n",
    "try:\n",
    "    connection = eng.connect()\n",
    "    results = connection.execute('select current_version()').fetchone()\n",
    "    print(\"Snowflake version: \",results[0])\n",
    "finally:\n",
    "    connection.close()\n",
    "\n",
    "    \n",
    "a = \"****\"\n",
    "b = \"***\"\n",
    "c = \"***\"\n",
    "\n",
    "warehouse = 'USE WAREHOUSE ' + a + ';'\n",
    "db = 'USE DATABASE ' + b + ';'\n",
    "schema = 'USE SCHEMA ' + c + ';'\n",
    "\n",
    "eng.execute(warehouse)\n",
    "eng.execute(db)\n",
    "eng.execute(schema)\n",
    "\n",
    "query = \"\"\"SELECT \n",
    "             ",
    "        \"\"\"\n",
    "\n",
    "df = pd.read_sql(query, eng)\n",
    "\n",
    "eng.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T08:56:49.375219Z",
     "start_time": "2018-08-24T08:56:49.057334Z"
    }
   }
